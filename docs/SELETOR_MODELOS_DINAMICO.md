
# üß† Seletor de Modelos Din√¢mico

## üéØ Objetivo
Este documento detalha a implementa√ß√£o do **seletor din√¢mico de modelos** no sistema, permitindo ao usu√°rio alternar entre diferentes motores e tamanhos de modelos de reconhecimento de fala.

---

## üîÅ Suporte a M√∫ltiplos Modelos

O sistema agora suporta os seguintes motores de IA:

| Motor        | Tipo       | Requer Internet | Processamento | Precis√£o |
|-------------|------------|------------------|----------------|-----------|
| `whisper_tiny` | OpenAI     | Sim              | CPU/GPU         | M√©dia     |
| `whisper_base` | OpenAI     | Sim              | CPU/GPU         | Boa       |
| `whisper_small`| OpenAI     | Sim              | CPU/GPU         | Alta      |
| `whisper_medium`| OpenAI    | Sim              | CPU/GPU         | Muito Alta|
| `whisper_large`| OpenAI     | Sim              | CPU/GPU         | M√°xima    |
| `vosk`         | Kaldi-based| N√£o              | Apenas CPU      | Alta      |

> üí° Todos os modelos podem ser usados **sem altera√ß√µes no c√≥digo**, apenas selecionando via interface gr√°fica.

---

## üß± Arquitetura Interna

### 1. **ModelManager**
Gerencia o cache de modelos para evitar carregamentos repetidos:
```python
class ModelManager:
    def __init__(self):
        self.loaded_models = {}  # Cache de modelos
        self.vosk_model_path = "vendor/vosk-model/"

    def get_model(self, model_name: str):
        # Carrega modelo se n√£o estiver em cache
```

### 2. **TranscriptionManager**
Lida com a transcri√ß√£o com base no nome do modelo:
```python
class TranscriptionManager:
    def __init__(self, model_name, model_manager, ...):
        self.model_name = model_name
        self.model_manager = model_manager
        self.model = self.model_manager.get_model(model_name)

    def _transcribe_with_whisper(self, temp_wav_file):
        # Usa PyTorch + CUDA se dispon√≠vel

    def _transcribe_with_vosk(self, temp_wav_file):
        # Progresso real com base na posi√ß√£o do √°udio
```

### 3. **Dispatcher de Transcri√ß√£o**
Seleciona automaticamente o motor correto:
```python
# No m√©todo _transcribe_single_file()
if self.model_name.startswith('whisper'):
    transcript_text = self._transcribe_with_whisper(temp_wav_file)
elif self.model_name == 'vosk':
    transcript_text = self._transcribe_with_vosk(temp_wav_file)
```

---

## üñ•Ô∏è Interface do Usu√°rio

### Localiza√ß√£o:
- Na barra superior da aplica√ß√£o desktop/web

### Op√ß√µes Dispon√≠veis:
- `whisper_tiny`: ideal para testes r√°pidos
- `whisper_base`: bom equil√≠brio (padr√£o)
- `whisper_large`: m√°xima precis√£o
- `vosk`: processamento offline r√°pido

### Funcionalidade:
- Atualiza automaticamente o modelo usado
- Mostra feedback visual durante mudan√ßa
- Mant√©m configura√ß√µes entre reinicializa√ß√µes

---

## ‚öôÔ∏è Configura√ß√£o Padr√£o

Se nenhum modelo for selecionado, o sistema usa:
```python
WHISPER_MODEL = load_whisper_model("base")  # PADR√ÉO
```

Voc√™ pode alterar isso editando:
```
app/routes.py
```

---

## üìà Compara√ß√£o de Performance

| Modelo        | Tamanho | Velocidade | Uso de RAM | GPU | Precis√£o |
|---------------|---------|------------|------------|-----|----------|
| `whisper_tiny`| 39MB    | ‚ö°‚ö°‚ö°‚ö°     | Baixo      | Opcional | ‚≠ê‚≠ê     |
| `whisper_base`| 74MB    | ‚ö°‚ö°‚ö°      | Baixo      | Opcional | ‚≠ê‚≠ê‚≠ê   |
| `whisper_small`| 244MB  | ‚ö°‚ö°       | M√©dio      | Recomendada | ‚≠ê‚≠ê‚≠ê‚≠ê |
| `whisper_medium`| 769MB | ‚ö°         | Alto       | Recomendada | ‚≠ê‚≠ê‚≠ê‚≠ê |
| `whisper_large`| 1550MB | üê¢         | Muito alto | Necess√°ria | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê |
| `vosk`        | ~1GB    | ‚ö°‚ö°‚ö°     | M√©dio      | N√£o | ‚≠ê‚≠ê‚≠ê     |

---

## üõ†Ô∏è Solu√ß√£o de Problemas

### Erro: "Model not found"
- **Whisper**: Verifique sua conex√£o com internet
- **Vosk**: Confirme que o modelo est√° em `vendor/vosk-model/`

### Erro: "CUDA out of memory"
- Use modelos menores (`whisper_tiny`, `whisper_base`)
- Desative uso de GPU nas configura√ß√µes
- Reduza tamanho dos arquivos processados

### Performance Lenta
- Troque para modelo menor
- Certifique-se de que o FFmpeg est√° otimizado
- Feche outros programas concorrentes

---

## üìå Benef√≠cios da Implementa√ß√£o

### Para Usu√°rios
- ‚úÖ Flexibilidade total na escolha do modelo
- ‚úÖ Interface intuitiva e amig√°vel
- ‚úÖ Processamento offline com Vosk
- ‚úÖ Otimiza√ß√£o por caso de uso (velocidade vs precis√£o)

### Para Desenvolvedores
- ‚úÖ Arquitetura modular e extens√≠vel
- ‚úÖ Cache inteligente para performance
- ‚úÖ C√≥digo limpo e bem estruturado
- ‚úÖ F√°cil adi√ß√£o de novos modelos

---

## üîÑ Pr√≥ximos Passos (Opcional)

| Melhoria                     | Descri√ß√£o                                  |
|------------------------------|--------------------------------------------|
| üß© Adicionar novos idiomas   | Permitir sele√ß√£o de idioma                 |
| üß≠ Suporte a HuggingFace     | Integra√ß√£o com mais modelos de IA          |
| üìä Estat√≠sticas de uso       | Mostrar qual modelo √© mais usado           |
| üß† Intelig√™ncia artificial   | Sugest√µes autom√°ticas de modelo            |
| üß™ Modo benchmark            | Comparar velocidade e precis√£o entre modelos|

---

## üìÑ Hist√≥rico de Atualiza√ß√µes

| Vers√£o | Data       | Descri√ß√£o                                |
|--------|------------|------------------------------------------|
| 1.0    | 2024-03-15 | Implementa√ß√£o inicial                    |
| 1.1    | 2024-03-18 | Adicionado Whisper Tiny e Base           |
| 1.2    | 2024-03-20 | Suporte completo a todos os modelos      |
| 1.3    | 2024-03-22 | Integra√ß√£o com interface gr√°fica         |
| 1.4    | 2024-03-25 | Cache inteligente e melhorias de desempenho |
| 1.5    | 2024-03-28 | Suporte a m√∫ltiplas threads              |
