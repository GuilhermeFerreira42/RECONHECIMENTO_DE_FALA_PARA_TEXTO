# Seletor de Modelos Din√¢mico - Documenta√ß√£o Completa

## üéØ Vis√£o Geral

O sistema agora suporta **m√∫ltiplos modelos de reconhecimento de fala** com um seletor din√¢mico na interface, permitindo que o usu√°rio escolha entre diferentes motores de transcri√ß√£o baseado em suas necessidades espec√≠ficas.

## üöÄ Funcionalidades Implementadas

### ‚úÖ **ModelManager (Gerenciador de Modelos)**
- Carregamento sob demanda de modelos
- Cache inteligente para evitar recarregamentos
- Suporte a Whisper (5 tamanhos) e Vosk
- Tratamento de erros robusto

### ‚úÖ **TranscriptionManager Aprimorado**
- Dispatcher autom√°tico baseado no modelo selecionado
- Progresso real para Vosk (processamento em chunks)
- Progresso simulado para Whisper (baseado em tempo estimado)
- Compatibilidade total com a interface existente

### ‚úÖ **Interface de Usu√°rio Flex√≠vel**
- Dropdown com 6 op√ß√µes de modelos
- Desabilita√ß√£o autom√°tica durante processamento
- Feedback visual do modelo selecionado
- Valida√ß√£o de sele√ß√£o obrigat√≥ria

## üìã Modelos Dispon√≠veis

### **Whisper (OpenAI)**
| Modelo | Tamanho | Velocidade | Precis√£o | Uso Recomendado |
|--------|---------|------------|----------|-----------------|
| `whisper_tiny` | 39MB | ‚ö°‚ö°‚ö°‚ö°‚ö° | ‚≠ê‚≠ê | Testes r√°pidos |
| `whisper_base` | 74MB | ‚ö°‚ö°‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê | Uso geral |
| `whisper_small` | 244MB | ‚ö°‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê‚≠ê | Alta precis√£o |
| `whisper_medium` | 769MB | ‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | Excelente qualidade |
| `whisper_large` | 1550MB | ‚ö° | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | M√°xima precis√£o |

### **Vosk (Offline)**
| Modelo | Tamanho | Velocidade | Precis√£o | Uso Recomendado |
|--------|---------|------------|----------|-----------------|
| `vosk` | ~1GB | ‚ö°‚ö°‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê | Processamento offline |

## üîß Arquitetura T√©cnica

### **Backend (Python)**

#### 1. ModelManager Class
```python
class ModelManager:
    def __init__(self):
        self.loaded_models = {}  # Cache de modelos
        self.vosk_model_path = "vendor/vosk-model/"
    
    def get_model(self, model_name: str):
        # Carrega modelo se n√£o estiver em cache
        # Suporte a whisper_* e vosk
```

#### 2. TranscriptionManager Aprimorado
```python
class TranscriptionManager:
    def __init__(self, model_name, model_manager, ...):
        # Aceita nome do modelo em vez do objeto
    
    def _transcribe_with_whisper(self, temp_wav_file):
        # Progresso simulado baseado em tempo estimado
    
    def _transcribe_with_vosk(self, temp_wav_file):
        # Progresso real em tempo real
```

#### 3. Dispatcher de Transcri√ß√£o
```python
# No m√©todo _transcribe_single_file()
if self.model_name.startswith('whisper'):
    transcript_text = self._transcribe_with_whisper(temp_wav_file)
elif self.model_name == 'vosk':
    transcript_text = self._transcribe_with_vosk(temp_wav_file)
```

### **Frontend (JavaScript/HTML)**

#### 1. Seletor de Modelo
```html
<select id="model-selector">
    <option value="whisper_base" selected>Whisper - Base (Equil√≠brio)</option>
    <option value="whisper_tiny">Whisper - Tiny (Mais R√°pido)</option>
    <!-- ... outras op√ß√µes ... -->
    <option value="vosk">Vosk (Offline/R√°pido)</option>
</select>
```

#### 2. Integra√ß√£o com Backend
```javascript
const modelName = modelSelector.value;
const requestBody = {
    file_list: fileList,
    dest_path: destPath,
    model_name: modelName  // Novo campo
};
```

## üéÆ Como Usar

### **Passo 1: Selecionar Modelo**
1. Abra a aplica√ß√£o
2. No cabe√ßalho, localize o dropdown "MODELO DE LINGUAGEM"
3. Escolha o modelo desejado:
   - **Whisper Base**: Bom equil√≠brio (padr√£o)
   - **Whisper Tiny**: Para testes r√°pidos
   - **Whisper Large**: Para m√°xima precis√£o
   - **Vosk**: Para processamento offline

### **Passo 2: Configurar Transcri√ß√£o**
1. Selecione pasta de origem e destino
2. Adicione arquivos √† fila
3. Configure op√ß√µes (manter estrutura, etc.)

### **Passo 3: Iniciar Processamento**
1. Clique em "INICIAR"
2. O modelo ser√° carregado automaticamente
3. A barra de progresso funcionar√° conforme o modelo:
   - **Vosk**: Progresso real em tempo real
   - **Whisper**: Progresso simulado baseado em estimativa

## üìä Compara√ß√£o de Performance

### **Progresso Individual**
| Modelo | Tipo de Progresso | Atualiza√ß√£o | Precis√£o |
|--------|-------------------|-------------|----------|
| Vosk | Real | Em tempo real | 100% precisa |
| Whisper | Simulado | Baseado em estimativa | ~90% precisa |

### **Velocidade de Processamento**
| Modelo | Velocidade Relativa | Mem√≥ria | GPU |
|--------|-------------------|---------|-----|
| whisper_tiny | 5x mais r√°pido | Baixa | Opcional |
| whisper_base | 3x mais r√°pido | M√©dia | Opcional |
| whisper_small | 2x mais r√°pido | M√©dia | Recomendado |
| whisper_medium | Padr√£o | Alta | Recomendado |
| whisper_large | Mais lento | Muito alta | Necess√°rio |
| vosk | R√°pido | M√©dia | N√£o |

## üîç Detalhes T√©cnicos

### **Cache de Modelos**
- Modelos s√£o carregados apenas uma vez
- Mantidos em mem√≥ria para reutiliza√ß√£o
- Libera√ß√£o autom√°tica quando n√£o utilizados

### **Estimativa de Tempo (Whisper)**
```python
file_size_mb = temp_wav_file.stat().st_size / (1024 * 1024)
estimated_duration_seconds = file_size_mb * 30  # ~1MB = 30s
progress_update_interval = estimated_duration_seconds / 20
```

### **Progresso Real (Vosk)**
```python
progress_percentage = min(95, int((wf.tell() / total_frames) * 100))
self.current_file_info["progress"] = progress_percentage
```

## üõ†Ô∏è Solu√ß√£o de Problemas

### **Erro: "Modelo n√£o encontrado"**
**Causa**: Modelo Vosk n√£o est√° na pasta `vendor/vosk-model/`
**Solu√ß√£o**: 
1. Verifique se a pasta existe
2. Baixe o modelo Vosk para portugu√™s
3. Extraia na pasta `vendor/vosk-model/`

### **Erro: "CUDA out of memory"**
**Causa**: Modelo Whisper muito grande para GPU
**Solu√ß√£o**:
1. Use modelo menor (`tiny`, `base`)
2. Processe arquivos menores
3. Feche outros aplicativos

### **Progresso Lento**
**Causa**: Modelo grande ou arquivo complexo
**Solu√ß√£o**:
1. Troque para modelo menor
2. Verifique se GPU est√° sendo usada
3. Divida arquivos grandes

## üìà Benef√≠cios da Implementa√ß√£o

### **Para Usu√°rios**
- ‚úÖ **Flexibilidade total** na escolha do modelo
- ‚úÖ **Progresso visual consistente** para todos os modelos
- ‚úÖ **Otimiza√ß√£o por caso de uso** (velocidade vs precis√£o)
- ‚úÖ **Processamento offline** com Vosk

### **Para Desenvolvedores**
- ‚úÖ **Arquitetura modular** e extens√≠vel
- ‚úÖ **Cache inteligente** para performance
- ‚úÖ **C√≥digo limpo** e bem estruturado
- ‚úÖ **F√°cil adi√ß√£o** de novos modelos

## üîÆ Pr√≥ximas Melhorias

### **Poss√≠veis Extens√µes**
1. **Detec√ß√£o autom√°tica** do melhor modelo baseado no arquivo
2. **Configura√ß√£o persistente** do modelo preferido
3. **Compara√ß√£o de resultados** entre modelos
4. **Suporte a mais motores** (Google Speech, Azure, etc.)

### **Otimiza√ß√µes Futuras**
1. **Carregamento paralelo** de modelos
2. **Compress√£o de modelos** para economizar espa√ßo
3. **Adapta√ß√£o autom√°tica** baseada em hardware dispon√≠vel

## üéâ Conclus√£o

O seletor de modelos din√¢mico transforma o sistema em uma ferramenta **profissional e flex√≠vel**, oferecendo:

- **6 op√ß√µes de modelos** para diferentes necessidades
- **Progresso visual consistente** independente do modelo
- **Arquitetura robusta** e facilmente extens√≠vel
- **Experi√™ncia de usu√°rio superior** com feedback claro

O sistema agora atende desde usu√°rios casuais (Whisper Tiny) at√© profissionais que precisam de m√°xima precis√£o (Whisper Large), mantendo a simplicidade de uso e a confiabilidade do processamento. 